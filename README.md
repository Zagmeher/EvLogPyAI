# EvLogPyAI ğŸ¤–

**Analisi Intelligente dei Log di Windows con AI**

EvLogPyAI Ã¨ un'applicazione Windows che estrae automaticamente i log del Visualizzatore Eventi, li invia a un workflow N8N integrato con Ollama AI per l'analisi, e presenta i risultati in un report HTML dettagliato.

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/python-3.10+-green)
![License](https://img.shields.io/badge/license-MIT-orange)

---

## âš¡ Avvio Rapido - 3 Comandi

> ğŸ“– **Guida dettagliata**: Vedi [QUICKSTART.md](QUICKSTART.md) per istruzioni passo-passo con screenshots

**Per far funzionare tutto, esegui in ordine:**

```powershell
# 1. Avvia Docker (Ollama + N8N)
.\start.ps1

# 2. Importa workflow N8N manualmente
# Vai su http://localhost:5678
# Import from File â†’ n8n/workflows/evlogpyai-workflow.json
# IMPORTANTE: Attiva il workflow (toggle in alto a destra â†’ VERDE)

# 3. Avvia l'applicazione
.\EvLogPyAI.exe
# Oppure: python trigger.py
```

**ğŸ¯ Ordine di Esecuzione:**
1. **start.ps1** â†’ Avvia container Docker + scarica modello AI (~10 min prima volta)
2. **N8N** â†’ Importa e attiva workflow manualmente (vedi [n8n/workflows/README.md](n8n/workflows/README.md))
3. **EvLogPyAI.exe** â†’ Avvia l'applicazione principale

---

## ğŸ“‹ Caratteristiche

âœ… **Interfaccia Grafica Moderna** - GUI intuitiva con CustomTkinter  
âœ… **Estrazione Log Windows** - Accesso diretto al Visualizzatore Eventi  
âœ… **Analisi AI Automatica** - Ollama analizza errori e propone soluzioni  
âœ… **Report HTML Formattati** - Output professionale con stile dark theme  
âœ… **Workflow N8N Integrato** - Automazione completa del processo  
âœ… **Callback Asincrono** - Non blocca l'applicazione durante l'analisi  

---

## ğŸš€ Installazione Completa

### Prerequisiti

- **Windows 10/11** (per accesso ai log di Windows)
- **Docker Desktop** installato e avviato
- **4GB RAM** disponibili per Ollama

### Installazione

#### Opzione 1: Eseguibile Pre-compilato (Consigliato)

1. Scarica l'ultima release da [GitHub Releases](https://github.com/zagmeher/EvLogPyAI/releases)
2. Estrai l'archivio in una cartella
3. Avvia Docker Desktop
4. Esegui lo script di avvio automatico:

```powershell
.\start.ps1
```

Questo script:
- âœ… Verifica che Docker sia attivo
- âœ… Avvia container Ollama e N8N
- âœ… Scarica automaticamente il modello AI (llama2)
- âœ… Apre N8N nel browser per configurazione

5. **IMPORTANTE**: Importa il workflow N8N:
   - Il browser si apre automaticamente su http://localhost:5678
   - Clicca su "Import from File"
   - Seleziona: `n8n/workflows/evlogpyai-workflow.json`
   - **ATTIVA** il workflow (toggle in alto a destra deve essere VERDE)

6. Lancia `EvLogPyAI.exe`

#### Opzione 2: Da Codice Sorgente

```powershell
# Clona il repository
git clone https://github.com/zagmeher/EvLogPyAI.git
cd EvLogPyAI

# Installa dipendenze Python
pip install -r requirements.txt

# Avvia Docker
docker-compose up -d

# Scarica modello Ollama
docker exec -it evlogpyai-ollama ollama pull llama2

# Importa workflow N8N (come sopra)

# Esegui l'applicazione
python trigger.py
```

---

## ğŸ“– Utilizzo

### 1. Avvia l'Applicazione

Doppio click su `EvLogPyAI.exe` o esegui `python trigger.py`

### 2. Compila il Form

- **Titolo Problema**: Breve descrizione (es. "Errore Secure Boot")
- **Categoria Log**: Seleziona da Application, Security, System, Setup, ForwardedEvents
- **Numero Righe**: Quanti eventi estrarre (es. 50)
- **Descrizione Issue**: Dettagli del problema riscontrato

### 3. Estrai i Log

Clicca su **"ğŸ“¥ Estrai Log"**. L'applicazione:
1. Legge i log dal Visualizzatore Eventi di Windows
2. Salva un file `.txt` sul Desktop
3. Avvia un server callback sulla porta 5050
4. Invia i dati a N8N

### 4. Attendi l'Analisi

- N8N riceve i dati e li formatta
- Ollama AI analizza i log (puÃ² richiedere 2-5 minuti)
- Il risultato viene inviato al callback di EvLogPyAI

### 5. Visualizza il Report

Il browser si apre automaticamente con un report HTML contenente:
- Diagnosi del problema
- Analisi degli errori piÃ¹ gravi
- Cause identificate
- Soluzioni proposte

---

## ğŸ—ï¸ Architettura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EvLogPyAI     â”‚ (Windows App)
â”‚   trigger.py    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /webhook
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   N8N Webhook   â”‚ (Docker Container)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Edit Fields    â”‚ (Formattazione)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI Agent      â”‚ (Ollama LLama2)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HTTP Request   â”‚ â†’ POST http://host.docker.internal:5050/callback
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Callback Server â”‚ (trigger.py:5050)
â”‚  HTML Generator â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Browser     â”‚ (Report HTML)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Configurazione Avanzata

### Cambio Porta Callback

Modifica in `trigger.py`:

```python
CALLBACK_PORT = 5050  # Cambia in una porta libera
```

Aggiorna anche l'URL in N8N nel nodo HTTP Request.

### Cambio Modello Ollama

Scarica un modello diverso:

```powershell
docker exec -it evlogpyai-ollama ollama pull mistral
```

Modifica il workflow N8N per usare il nuovo modello.

### Timeout Analisi AI

Modifica in `trigger.py` (riga ~1237):

```python
timeout=300  # 300 secondi = 5 minuti
```

---

## ğŸ“ Struttura Progetto

```
EvLogPyAI/
â”œâ”€â”€ trigger.py                  # Applicazione principale
â”œâ”€â”€ requirements.txt            # Dipendenze Python
â”œâ”€â”€ setup.py                    # Script build .exe
â”œâ”€â”€ docker-compose.yml          # Configurazione Docker
â”œâ”€â”€ README.md                   # Questo file
â”œâ”€â”€ LICENSE                     # Licenza MIT
â”œâ”€â”€ .gitignore                  # File da ignorare in Git
â”œâ”€â”€ n8n/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ evlogpyai-workflow.json  # Workflow N8N
â””â”€â”€ docs/
    â”œâ”€â”€ INSTALLATION.md         # Guida installazione dettagliata
    â””â”€â”€ screenshots/            # Screenshot applicazione
```

---

## ğŸ”§ Troubleshooting

### Errore "ECONNREFUSED" da N8N

**Problema**: N8N non riesce a connettersi al callback server.

**Soluzione**:
1. Verifica che EvLogPyAI sia in esecuzione
2. Verifica di aver cliccato "Estrai Log" (avvia il callback server)
3. Controlla che l'URL in N8N sia: `={{ $('Webhook').item.json.callback_url }}`

### Ollama Lento

**Problema**: L'analisi richiede troppo tempo.

**Soluzione**:
- Usa un modello piÃ¹ piccolo (es. `ollama pull phi`)
- Aumenta RAM allocata a Docker (Settings â†’ Resources â†’ Memory: 8GB)

### Log Non Trovati

**Problema**: "Nessun log trovato" dopo l'estrazione.

**Soluzione**:
- Esegui EvLogPyAI come **Amministratore** (tasto destro â†’ "Esegui come amministratore")
- I log di Security richiedono privilegi elevati

## ğŸ“„ Licenza

Distribuito sotto licenza MIT. Vedi `LICENSE` per maggiori informazioni.

---

## ğŸ‘¤ Autore

**Il Tuo Nome**
- GitHub: https://github.com/Zagmeher
- Email: info@angeloiandolo.it
---

## ğŸ™ Ringraziamenti

- [CustomTkinter](https://github.com/TomSchimansky/CustomTkinter) - GUI moderna per Python
- [Ollama](https://ollama.ai/) - Modelli AI locali
- [N8N](https://n8n.io/) - Workflow automation
- [PyWin32](https://github.com/mhammond/pywin32) - Accesso API Windows

---

## ğŸ“Š Statistiche

![Stars](https://img.shields.io/github/stars/tuousername/EvLogPyAI?style=social)
![Forks](https://img.shields.io/github/forks/tuousername/EvLogPyAI?style=social)
![Issues](https://img.shields.io/github/issues/tuousername/EvLogPyAI)

---

**Fatto con â¤ï¸ per semplificare l'analisi dei log di Windows**
